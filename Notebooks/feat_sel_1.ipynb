{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context of the notebook \n",
    "Tasks performed: \n",
    "- Choose which algorithm is the best to perform feature selection \n",
    "- Training and predictions are performed on the 3 datasets after feature selection was done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic python libraries\n",
    "import os \n",
    "import patoolib\n",
    "from glob import glob \n",
    "from multiprocessing.pool import Pool\n",
    "import warnings\n",
    "import struct\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Biological libraries \n",
    "from biopandas.pdb import PandasPdb\n",
    "from biopandas.mol2 import PandasMol2\n",
    "import mol2vec\n",
    "import prot2vec\n",
    "\n",
    "# Regular DS libraries \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "# AI libraries \n",
    "import sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat1 = \"C:/Users/redha.cherif_artefac/GitHub_perso/Research_project/Input/training_data/train_dat1_baseline_301022.parquet\"\n",
    "dat2 = \"C:/Users/redha.cherif_artefac/GitHub_perso/Research_project/Input/training_data/train_dat2_baseline_301022.parquet\"\n",
    "dat3 = \"C:/Users/redha.cherif_artefac/GitHub_perso/Research_project/Input/training_data/train_dat3_baseline_301022.parquet\"\n",
    "test = \"C:/Users/redha.cherif_artefac/GitHub_perso/Research_project/Input/test_data/test_set_f_301022.parquet\"\n",
    "\n",
    "train_dat1_baseline_301022 = pd.read_parquet(dat1)\n",
    "train_dat2_baseline_301022 = pd.read_parquet(dat2)\n",
    "train_dat3_baseline_301022 = pd.read_parquet(dat3)\n",
    "test_set_f_301022 = pd.read_parquet(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error # to measure the capacity of the algo to predict from the train \n",
    "def rmse(y_actual_test,y_predicted_test):\n",
    "    return np.sqrt(mean_squared_error(y_actual_test,y_predicted_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the algorithm wrapped by RFE: https://machinelearningmastery.com/rfe-feature-selection-in-python/ \n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset(dataset):\n",
    "    X = dataset.drop(['pdb_code','pKd_or_pKi'],axis=1)\n",
    "    y = dataset['pKd_or_pKi']\n",
    "    return X, y\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\t# lr\n",
    "\trfe = RFE(estimator=LinearRegression(), n_features_to_select=5)\n",
    "\tmodel = DecisionTreeRegressor()\n",
    "\tmodels['lr'] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "\t# cart\n",
    "\trfe = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=5)\n",
    "\tmodel = DecisionTreeRegressor()\n",
    "\tmodels['cart'] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "\t# rf\n",
    "\trfe = RFE(estimator=RandomForestRegressor(), n_features_to_select=5)\n",
    "\tmodel = DecisionTreeRegressor()\n",
    "\tmodels['rf'] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "\t# gbm\n",
    "\trfe = RFE(estimator=GradientBoostingRegressor(), n_features_to_select=5)\n",
    "\tmodel = DecisionTreeRegressor()\n",
    "\tmodels['gbm'] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "\treturn models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y, test):\n",
    "\tmodel_fit = model.fit(X,y)\n",
    "\tpreds = model_fit.predict(test.drop(['pdb_code','pKd_or_pKi'],axis=1))\n",
    "\tscores = rmse(test['pKd_or_pKi'],preds)\n",
    "\t#cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=1)\n",
    "\t#scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr,2.219\n",
      "cart,2.808\n",
      "rf,2.612\n",
      "gbm,2.63\n"
     ]
    }
   ],
   "source": [
    "# define dataset\n",
    "X, y = get_dataset(train_dat1_baseline_301022)\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model, X, y, test_set_f_301022)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint(f\"{name},{round(scores,3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can see that linear regression is the best algorithm to perform feature selection as it has the lowest RMSE.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for dataset 1\n",
      "Score : -2.16, std: 1.171\n",
      "\n",
      "Performance for dataset 2\n",
      "Score : -1.691, std: 0.065\n",
      "\n",
      "Performance for dataset 3\n",
      "Score : -2.115, std: 0.878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# automatically select the number of features for RFE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# define dataset\n",
    "datasets = [train_dat1_baseline_301022, train_dat2_baseline_301022, train_dat3_baseline_301022]\n",
    "for i in range(len(datasets)):\n",
    "    X, y = get_dataset(datasets[i])\n",
    "    # create pipeline\n",
    "    rfe = RFECV(estimator=LinearRegression())\n",
    "    model = LinearRegression()\n",
    "    pipeline = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    # evaluate model\n",
    "    cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "    n_scores = cross_val_score(pipeline, X, y, scoring='neg_root_mean_squared_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    # report performance\n",
    "    print(f\"Performance for dataset {i+1}\")\n",
    "    print(f\"Score : {round(mean(n_scores),3)}, std: {round(std(n_scores),3)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature selection for dataset 1:\n",
      "Total nb of feature: 132\n",
      "Nb of selected features: 37\n",
      "\n",
      "Feature selection for dataset 2:\n",
      "Total nb of feature: 132\n",
      "Nb of selected features: 78\n",
      "\n",
      "Feature selection for dataset 3:\n",
      "Total nb of feature: 132\n",
      "Nb of selected features: 54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = [train_dat1_baseline_301022, train_dat2_baseline_301022, train_dat3_baseline_301022]\n",
    "selected_feats_dats = []\n",
    "test_sets = []\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "    X, y = get_dataset(datasets[i])\n",
    "    # fit RFE\n",
    "    rfe.fit(X, y)\n",
    "    # Nb of features selected \n",
    "    print(f'Feature selection for dataset {i+1}:')\n",
    "    print(f\"Total nb of feature: {rfe.n_features_in_}\")\n",
    "    print(f\"Nb of selected features: {rfe.n_features_}\")\n",
    "    print()\n",
    "    # summarize all features\n",
    "    #for i in range(X.shape[1]):\n",
    "    #\tprint('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))\n",
    "\n",
    "    # Get columns to keep and create new dataframe with those only\n",
    "    selected_feats = rfe.get_support(indices=True)\n",
    "    selected_feats = np.insert(selected_feats,0,0)\n",
    "    selected_feats = np.insert(selected_feats,len(selected_feats),datasets[i].shape[1]-1)\n",
    "    selected_feats = np.unique(selected_feats)\n",
    "    selected_feats_dat = datasets[i].iloc[:,selected_feats]\n",
    "    test_set = test_set_f_301022.iloc[:,selected_feats]\n",
    "    selected_feats_dats.append(selected_feats_dat)\n",
    "    test_sets.append(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error # to measure the capacity of the algo to predict from the train \n",
    "from scipy.stats import pearsonr #to measure the correlation between the predicted constants and the ones in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_actual_test,y_predicted_test):\n",
    "    return np.sqrt(mean_squared_error(y_actual_test,y_predicted_test))\n",
    "\n",
    "def pearson(y_actual_train,y_predicted_train):\n",
    "    return pearsonr(y_actual_train,y_predicted_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "linReg1 = LinearRegression()\n",
    "linReg2 = LinearRegression()\n",
    "linReg3 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainings_sets = [(selected_feats_dats[0].drop(['pdb_code','pKd_or_pKi'],axis=1),selected_feats_dats[0]['pKd_or_pKi']),(selected_feats_dats[1].drop(['pdb_code','pKd_or_pKi'],axis=1),selected_feats_dats[1]['pKd_or_pKi']),(selected_feats_dats[2].drop(['pdb_code','pKd_or_pKi'],axis=1),selected_feats_dats[2]['pKd_or_pKi'])]\n",
    "linReg_fit1 = linReg1.fit(trainings_sets[0][0],trainings_sets[0][1])\n",
    "linReg_fit2 = linReg2.fit(trainings_sets[1][0],trainings_sets[1][1])\n",
    "linReg_fit3 = linReg3.fit(trainings_sets[2][0],trainings_sets[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat1_preds = linReg_fit1.predict(test_sets[0].drop(['pdb_code','pKd_or_pKi'],axis=1))\n",
    "dat2_preds = linReg_fit2.predict(test_sets[1].drop(['pdb_code','pKd_or_pKi'],axis=1))\n",
    "dat3_preds = linReg_fit3.predict(test_sets[2].drop(['pdb_code','pKd_or_pKi'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.335959980615138\n",
      "20.835570990735324\n",
      "19.05233989106812\n"
     ]
    }
   ],
   "source": [
    "dat1_rmse = rmse(test_sets[0]['pKd_or_pKi'],dat1_preds) \n",
    "dat2_rmse = rmse(test_sets[1]['pKd_or_pKi'],dat2_preds) \n",
    "dat3_rmse = rmse(test_sets[2]['pKd_or_pKi'],dat3_preds)\n",
    "print(dat1_rmse)\n",
    "print(dat2_rmse)\n",
    "print(dat3_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.4610059561731793, 6.711643848970794e-119)\n",
      "(0.5084079821666755, 2.9801876191512593e-156)\n",
      "(0.49421772808297776, 2.589267817197755e-149)\n"
     ]
    }
   ],
   "source": [
    "dat1_preds_train = linReg_fit1.predict(trainings_sets[0][0])\n",
    "dat2_preds_train = linReg_fit2.predict(trainings_sets[1][0])\n",
    "dat3_preds_train = linReg_fit3.predict(trainings_sets[2][0])\n",
    "\n",
    "dat1_pearson = pearson(trainings_sets[0][1],dat1_preds_train) \n",
    "dat2_pearson = pearson(trainings_sets[1][1],dat2_preds_train) \n",
    "dat3_pearson = pearson(trainings_sets[2][1],dat3_preds_train)\n",
    "print(dat1_pearson)\n",
    "print(dat2_pearson)\n",
    "print(dat3_pearson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat1_preds = pd.DataFrame(dat1_preds,columns=['score'])\n",
    "dat1_preds[\"#code\"] = test_sets[0]['pdb_code']\n",
    "dat1_preds = dat1_preds[['#code','score']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2_preds = pd.DataFrame(dat2_preds,columns=['score'])\n",
    "dat2_preds[\"#code\"] = test_sets[1]['pdb_code']\n",
    "dat2_preds = dat2_preds[['#code','score']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3_preds = pd.DataFrame(dat3_preds,columns=['score'])\n",
    "dat3_preds[\"#code\"] = test_sets[2]['pdb_code']\n",
    "dat3_preds = dat3_preds[['#code','score']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_preds_mean = pd.DataFrame(dat3_preds,columns=['score'])\n",
    "dat_preds_mean[\"#code\"] = test_sets[0]['pdb_code']\n",
    "dat_preds_mean = dat_preds_mean[['#code','score']] \n",
    "\n",
    "dat_preds_mean['score'] = dat1_preds['score'] + dat2_preds['score'] + dat3_preds['score']\n",
    "dat_preds_mean['score'] = dat_preds_mean['score'] / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat1_preds.to_csv('feats_sel_1_preds_dat1_011122.dat',index=False)\n",
    "dat2_preds.to_csv('feats_sel_1_preds_dat2_011122.dat',index=False)\n",
    "dat3_preds.to_csv('feats_sel_1_preds_dat3_011122.dat',index=False)\n",
    "dat_preds_mean.to_csv('feats_sel_1_preds_mean_011122.dat',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(linReg_fit3, open('linReg_dat3_011122.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sets[2].to_parquet('test_dat3_feats_sel1_011122.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb_code</th>\n",
       "      <th>lig_I_atom_count</th>\n",
       "      <th>lig_C.1_atom_count</th>\n",
       "      <th>lig_C.2_atom_mean</th>\n",
       "      <th>lig_C.3_atom_mean</th>\n",
       "      <th>lig_H_atom_mean</th>\n",
       "      <th>lig_N.4_atom_mean</th>\n",
       "      <th>lig_N.am_atom_mean</th>\n",
       "      <th>lig_O.co2_atom_mean</th>\n",
       "      <th>lig_C.ar_atom_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>lig_nb_mean_double_diff</th>\n",
       "      <th>lig_nb_triple_bonds</th>\n",
       "      <th>lig_mean_triple_bonds</th>\n",
       "      <th>lig_nb_mean_triple_diff</th>\n",
       "      <th>lig_nb_ar_bonds</th>\n",
       "      <th>lig_mean_ar_bonds</th>\n",
       "      <th>lig_nb_mean_ar_diff</th>\n",
       "      <th>lig_nb_am_bonds</th>\n",
       "      <th>lig_mean_am_bonds</th>\n",
       "      <th>pKd_or_pKi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1a30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.958333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>5.875000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>4.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1bcu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>15.448276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1bzc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>...</td>\n",
       "      <td>1.954545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>15.636364</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>4.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1c5z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>7.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1e66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>10.744186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>5aba</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>5.882353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>5c28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>5.739130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>5c2h</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>...</td>\n",
       "      <td>1.965517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>16.706897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>5dwr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>17.694915</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>11.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>5tmn</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>...</td>\n",
       "      <td>1.968750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>9.843750</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>8.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    pdb_code  lig_I_atom_count  lig_C.1_atom_count  lig_C.2_atom_mean  \\\n",
       "0       1a30               0.0                 0.0           0.102041   \n",
       "1       1bcu               0.0                 0.0           0.000000   \n",
       "2       1bzc               0.0                 0.0           0.069767   \n",
       "3       1c5z               0.0                 0.0           0.000000   \n",
       "4       1e66               0.0                 0.0           0.050000   \n",
       "..       ...               ...                 ...                ...   \n",
       "280     5aba               0.0                 0.0           0.000000   \n",
       "281     5c28               0.0                 0.0           0.000000   \n",
       "282     5c2h               0.0                 0.0           0.054545   \n",
       "283     5dwr               0.0                 0.0           0.017857   \n",
       "284     5tmn               0.0                 0.0           0.046875   \n",
       "\n",
       "     lig_C.3_atom_mean  lig_H_atom_mean  lig_N.4_atom_mean  \\\n",
       "0             0.204082         0.469388           0.020408   \n",
       "1             0.000000         0.407407           0.000000   \n",
       "2             0.093023         0.325581           0.000000   \n",
       "3             0.000000         0.500000           0.000000   \n",
       "4             0.175000         0.475000           0.000000   \n",
       "..                 ...              ...                ...   \n",
       "280           0.224490         0.530612           0.040816   \n",
       "281           0.181818         0.454545           0.000000   \n",
       "282           0.127273         0.436364           0.000000   \n",
       "283           0.125000         0.428571           0.017857   \n",
       "284           0.187500         0.500000           0.000000   \n",
       "\n",
       "     lig_N.am_atom_mean  lig_O.co2_atom_mean  lig_C.ar_atom_mean  ...  \\\n",
       "0              0.040816             0.122449            0.000000  ...   \n",
       "1              0.000000             0.000000            0.481481  ...   \n",
       "2              0.046512             0.116279            0.232558  ...   \n",
       "3              0.000000             0.000000            0.333333  ...   \n",
       "4              0.000000             0.000000            0.225000  ...   \n",
       "..                  ...                  ...                 ...  ...   \n",
       "280            0.000000             0.000000            0.122449  ...   \n",
       "281            0.000000             0.000000            0.181818  ...   \n",
       "282            0.000000             0.000000            0.236364  ...   \n",
       "283            0.017857             0.000000            0.285714  ...   \n",
       "284            0.046875             0.062500            0.093750  ...   \n",
       "\n",
       "     lig_nb_mean_double_diff  lig_nb_triple_bonds  lig_mean_triple_bonds  \\\n",
       "0                   1.958333                  0.0                    0.0   \n",
       "1                   0.000000                  0.0                    0.0   \n",
       "2                   1.954545                  0.0                    0.0   \n",
       "3                   0.000000                  0.0                    0.0   \n",
       "4                   0.976744                  0.0                    0.0   \n",
       "..                       ...                  ...                    ...   \n",
       "280                 0.000000                  0.0                    0.0   \n",
       "281                 0.000000                  0.0                    0.0   \n",
       "282                 1.965517                  0.0                    0.0   \n",
       "283                 0.983051                  0.0                    0.0   \n",
       "284                 1.968750                  0.0                    0.0   \n",
       "\n",
       "     lig_nb_mean_triple_diff  lig_nb_ar_bonds  lig_mean_ar_bonds  \\\n",
       "0                        0.0              6.0           0.125000   \n",
       "1                        0.0             16.0           0.551724   \n",
       "2                        0.0             16.0           0.363636   \n",
       "3                        0.0              8.0           0.444444   \n",
       "4                        0.0             11.0           0.255814   \n",
       "..                       ...              ...                ...   \n",
       "280                      0.0              6.0           0.117647   \n",
       "281                      0.0              6.0           0.260870   \n",
       "282                      0.0             17.0           0.293103   \n",
       "283                      0.0             18.0           0.305085   \n",
       "284                      0.0             10.0           0.156250   \n",
       "\n",
       "     lig_nb_mean_ar_diff  lig_nb_am_bonds  lig_mean_am_bonds  pKd_or_pKi  \n",
       "0               5.875000              2.0           0.041667        4.30  \n",
       "1              15.448276              0.0           0.000000        3.28  \n",
       "2              15.636364              2.0           0.045455        4.92  \n",
       "3               7.555556              0.0           0.000000        4.01  \n",
       "4              10.744186              0.0           0.000000        9.89  \n",
       "..                   ...              ...                ...         ...  \n",
       "280             5.882353              0.0           0.000000        2.98  \n",
       "281             5.739130              0.0           0.000000        5.66  \n",
       "282            16.706897              0.0           0.000000       11.09  \n",
       "283            17.694915              1.0           0.016949       11.22  \n",
       "284             9.843750              3.0           0.046875        8.04  \n",
       "\n",
       "[285 rows x 39 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('research_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc4d8e01cfb450a488e2d54538a370ca597c6c8157a9d6914f36157428d80e7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
